{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x24110dccd48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x24110ebe0c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\", distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.layers.Dense(300, kernel_initializer=\"he_nomal\")\n",
    "# keras.layers.LeakyRelu()\n",
    "\n",
    "# keras.layers.Dense(300, kernel_initializer=\"he_nomal\")\n",
    "# keras.layers.PReKu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domes\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1402: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "# optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.9248 - accuracy: 0.6994 - val_loss: 0.3895 - val_accuracy: 0.8665\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3651 - accuracy: 0.8745 - val_loss: 0.3287 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3182 - accuracy: 0.8895 - val_loss: 0.3014 - val_accuracy: 0.8994\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3049 - accuracy: 0.8956 - val_loss: 0.2894 - val_accuracy: 0.9021\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2804 - accuracy: 0.9026 - val_loss: 0.2775 - val_accuracy: 0.9061\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2701 - accuracy: 0.9076 - val_loss: 0.2735 - val_accuracy: 0.9063\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2626 - accuracy: 0.9096 - val_loss: 0.2721 - val_accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2610 - accuracy: 0.9122 - val_loss: 0.2589 - val_accuracy: 0.9136\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2558 - accuracy: 0.9107 - val_loss: 0.2562 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2511 - accuracy: 0.9137 - val_loss: 0.2543 - val_accuracy: 0.9155\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2431 - accuracy: 0.9172 - val_loss: 0.2497 - val_accuracy: 0.9158\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 0.2514 - val_accuracy: 0.9128\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2360 - accuracy: 0.9179 - val_loss: 0.2447 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2266 - accuracy: 0.9232 - val_loss: 0.2416 - val_accuracy: 0.9178\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2225 - accuracy: 0.9240 - val_loss: 0.2448 - val_accuracy: 0.9188\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2260 - accuracy: 0.9214 - val_loss: 0.2386 - val_accuracy: 0.9195\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2191 - accuracy: 0.9253 - val_loss: 0.2407 - val_accuracy: 0.9183\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2171 - accuracy: 0.9252 - val_loss: 0.2432 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2181 - accuracy: 0.9245 - val_loss: 0.2332 - val_accuracy: 0.9208\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2113 - accuracy: 0.9276 - val_loss: 0.2333 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 1.0360 - accuracy: 0.4975 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5883 - accuracy: 0.6971 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4380 - accuracy: 0.8854 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4021 - accuracy: 0.8712 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3361 - accuracy: 0.9348 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3113 - accuracy: 0.9233 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2817 - accuracy: 0.9299 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2632 - accuracy: 0.9379 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2373 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2229 - accuracy: 0.9657 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2155 - accuracy: 0.9590 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1834 - accuracy: 0.9738 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 0.9828 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1527 - accuracy: 0.9915 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 0.9904 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1473 - accuracy: 0.9937 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1412 - accuracy: 0.9944 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1242 - accuracy: 0.9931 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1224 - accuracy: 0.9931 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1096 - accuracy: 0.9912 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6170 - accuracy: 0.6184 - val_loss: 0.5860 - val_accuracy: 0.6318\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5562 - accuracy: 0.6583 - val_loss: 0.5482 - val_accuracy: 0.6704\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4902 - accuracy: 0.7509 - val_loss: 0.5160 - val_accuracy: 0.7069\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4903 - accuracy: 0.7405 - val_loss: 0.4871 - val_accuracy: 0.7292\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.4387 - accuracy: 0.7774 - val_loss: 0.3469 - val_accuracy: 0.8631\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2976 - accuracy: 0.9143 - val_loss: 0.2609 - val_accuracy: 0.9249\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2036 - accuracy: 0.9777 - val_loss: 0.2115 - val_accuracy: 0.9554\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1754 - accuracy: 0.9789 - val_loss: 0.1795 - val_accuracy: 0.9696\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1349 - accuracy: 0.9809 - val_loss: 0.1565 - val_accuracy: 0.9757\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1172 - accuracy: 0.9973 - val_loss: 0.1396 - val_accuracy: 0.9807\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1139 - accuracy: 0.9931 - val_loss: 0.1269 - val_accuracy: 0.9838\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1001 - accuracy: 0.9931 - val_loss: 0.1166 - val_accuracy: 0.9858\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9888\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9899\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9899\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9899\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                          validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                          validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06832191348075867, 0.9929999709129333]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epochs):\n",
    "    return 0.01 * 0.1 **(epochs / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epochs):\n",
    "        return lr0 * 0.1 **(epochs / s)\n",
    "    return exponential_decay_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhistory = model.fit(X_train, y_train, epochs=n_epochs,\\n                   validation_data(X_valid, y_valid),\\n                   callbacks=[lr_scheduler])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "'''\n",
    "history = model.fit(X_train, y_train, epochs=n_epochs,\n",
    "                   validation_data(X_valid, y_valid),\n",
    "                   callbacks=[lr_scheduler])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1 ** (1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ns = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size=32)\\nlearning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\\noptimizer = keras.optimizers.SGD(learning_rate)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size=32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iterations = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "        \n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1) / (iter2 - iter1) + rate1)\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        \n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration, self.max_rate, self.start_rate)\n",
    "        \n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations, self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation='elu',\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation=\"elu\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\", kernel_initializer='glorot_uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
