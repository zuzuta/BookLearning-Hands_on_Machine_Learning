{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x24110dccd48>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x24110ebe0c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode=\"fan_avg\", distribution=\"uniform\")\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.layers.Dense(300, kernel_initializer=\"he_nomal\")\n",
    "# keras.layers.LeakyRelu()\n",
    "\n",
    "# keras.layers.Dense(300, kernel_initializer=\"he_nomal\")\n",
    "# keras.layers.PReKu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domes\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:1402: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "# optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.9248 - accuracy: 0.6994 - val_loss: 0.3895 - val_accuracy: 0.8665\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3651 - accuracy: 0.8745 - val_loss: 0.3287 - val_accuracy: 0.8824\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3182 - accuracy: 0.8895 - val_loss: 0.3014 - val_accuracy: 0.8994\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3049 - accuracy: 0.8956 - val_loss: 0.2894 - val_accuracy: 0.9021\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2804 - accuracy: 0.9026 - val_loss: 0.2775 - val_accuracy: 0.9061\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2701 - accuracy: 0.9076 - val_loss: 0.2735 - val_accuracy: 0.9063\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2626 - accuracy: 0.9096 - val_loss: 0.2721 - val_accuracy: 0.9083\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2610 - accuracy: 0.9122 - val_loss: 0.2589 - val_accuracy: 0.9136\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2558 - accuracy: 0.9107 - val_loss: 0.2562 - val_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2511 - accuracy: 0.9137 - val_loss: 0.2543 - val_accuracy: 0.9155\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2431 - accuracy: 0.9172 - val_loss: 0.2497 - val_accuracy: 0.9158\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2422 - accuracy: 0.9171 - val_loss: 0.2514 - val_accuracy: 0.9128\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2360 - accuracy: 0.9179 - val_loss: 0.2447 - val_accuracy: 0.9160\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2266 - accuracy: 0.9232 - val_loss: 0.2416 - val_accuracy: 0.9178\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2225 - accuracy: 0.9240 - val_loss: 0.2448 - val_accuracy: 0.9188\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2260 - accuracy: 0.9214 - val_loss: 0.2386 - val_accuracy: 0.9195\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2191 - accuracy: 0.9253 - val_loss: 0.2407 - val_accuracy: 0.9183\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2171 - accuracy: 0.9252 - val_loss: 0.2432 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2181 - accuracy: 0.9245 - val_loss: 0.2332 - val_accuracy: 0.9208\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2113 - accuracy: 0.9276 - val_loss: 0.2333 - val_accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 1.0360 - accuracy: 0.4975 - val_loss: 0.6314 - val_accuracy: 0.6004\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5883 - accuracy: 0.6971 - val_loss: 0.4784 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4380 - accuracy: 0.8854 - val_loss: 0.4102 - val_accuracy: 0.8945\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4021 - accuracy: 0.8712 - val_loss: 0.3647 - val_accuracy: 0.9178\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3361 - accuracy: 0.9348 - val_loss: 0.3300 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.3113 - accuracy: 0.9233 - val_loss: 0.3019 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2817 - accuracy: 0.9299 - val_loss: 0.2804 - val_accuracy: 0.9422\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2632 - accuracy: 0.9379 - val_loss: 0.2606 - val_accuracy: 0.9473\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.2373 - accuracy: 0.9481 - val_loss: 0.2428 - val_accuracy: 0.9523\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2229 - accuracy: 0.9657 - val_loss: 0.2281 - val_accuracy: 0.9544\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2155 - accuracy: 0.9590 - val_loss: 0.2150 - val_accuracy: 0.9584\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1834 - accuracy: 0.9738 - val_loss: 0.2036 - val_accuracy: 0.9584\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 0.9828 - val_loss: 0.1931 - val_accuracy: 0.9615\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1527 - accuracy: 0.9915 - val_loss: 0.1838 - val_accuracy: 0.9635\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1595 - accuracy: 0.9904 - val_loss: 0.1746 - val_accuracy: 0.9686\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1473 - accuracy: 0.9937 - val_loss: 0.1674 - val_accuracy: 0.9686\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1412 - accuracy: 0.9944 - val_loss: 0.1604 - val_accuracy: 0.9706\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1242 - accuracy: 0.9931 - val_loss: 0.1539 - val_accuracy: 0.9706\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.1224 - accuracy: 0.9931 - val_loss: 0.1482 - val_accuracy: 0.9716\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1096 - accuracy: 0.9912 - val_loss: 0.1431 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6170 - accuracy: 0.6184 - val_loss: 0.5860 - val_accuracy: 0.6318\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5562 - accuracy: 0.6583 - val_loss: 0.5482 - val_accuracy: 0.6704\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.4902 - accuracy: 0.7509 - val_loss: 0.5160 - val_accuracy: 0.7069\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4903 - accuracy: 0.7405 - val_loss: 0.4871 - val_accuracy: 0.7292\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.4387 - accuracy: 0.7774 - val_loss: 0.3469 - val_accuracy: 0.8631\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2976 - accuracy: 0.9143 - val_loss: 0.2609 - val_accuracy: 0.9249\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.2036 - accuracy: 0.9777 - val_loss: 0.2115 - val_accuracy: 0.9554\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1754 - accuracy: 0.9789 - val_loss: 0.1795 - val_accuracy: 0.9696\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1349 - accuracy: 0.9809 - val_loss: 0.1565 - val_accuracy: 0.9757\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1172 - accuracy: 0.9973 - val_loss: 0.1396 - val_accuracy: 0.9807\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.1139 - accuracy: 0.9931 - val_loss: 0.1269 - val_accuracy: 0.9838\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1001 - accuracy: 0.9931 - val_loss: 0.1166 - val_accuracy: 0.9858\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9888\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0773 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9899\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9899\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9899\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9899\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0494 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9899\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0544 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9899\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                          validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                          validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06832191348075867, 0.9929999709129333]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epochs):\n",
    "    return 0.01 * 0.1 **(epochs / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epochs):\n",
    "        return lr0 * 0.1 **(epochs / s)\n",
    "    return exponential_decay_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhistory = model.fit(X_train, y_train, epochs=n_epochs,\\n                   validation_data(X_valid, y_valid),\\n                   callbacks=[lr_scheduler])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "\n",
    "'''\n",
    "history = model.fit(X_train, y_train, epochs=n_epochs,\n",
    "                   validation_data(X_valid, y_valid),\n",
    "                   callbacks=[lr_scheduler])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1 ** (1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ns = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size=32)\\nlearning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\\noptimizer = keras.optimizers.SGD(learning_rate)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size=32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iterations = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "        \n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1) / (iter2 - iter1) + rate1)\n",
    "    \n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        \n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration, self.max_rate, self.start_rate)\n",
    "        \n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations, self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation='elu',\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation=\"elu\",\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\", kernel_initializer='glorot_uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.8023 - accuracy: 0.7146 - val_loss: 0.5778 - val_accuracy: 0.8446\n",
      "Epoch 2/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5662 - accuracy: 0.7904 - val_loss: 0.5146 - val_accuracy: 0.8528\n",
      "Epoch 3/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5260 - accuracy: 0.8062 - val_loss: 0.4878 - val_accuracy: 0.8604\n",
      "Epoch 4/20\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5125 - accuracy: 0.8098 - val_loss: 0.4810 - val_accuracy: 0.8576\n",
      "Epoch 5/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5074 - accuracy: 0.8126 - val_loss: 0.4250 - val_accuracy: 0.8686\n",
      "Epoch 6/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4789 - accuracy: 0.8201 - val_loss: 0.4600 - val_accuracy: 0.8640\n",
      "Epoch 7/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4721 - accuracy: 0.8273 - val_loss: 0.4672 - val_accuracy: 0.8624\n",
      "Epoch 8/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4570 - accuracy: 0.8300 - val_loss: 0.4191 - val_accuracy: 0.8678\n",
      "Epoch 9/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4625 - accuracy: 0.8292 - val_loss: 0.4328 - val_accuracy: 0.8736\n",
      "Epoch 10/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4548 - accuracy: 0.8308 - val_loss: 0.4364 - val_accuracy: 0.8662\n",
      "Epoch 11/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4459 - accuracy: 0.8344 - val_loss: 0.4409 - val_accuracy: 0.8708\n",
      "Epoch 12/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4412 - accuracy: 0.8367 - val_loss: 0.5234 - val_accuracy: 0.8564\n",
      "Epoch 13/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4324 - accuracy: 0.8388 - val_loss: 0.4335 - val_accuracy: 0.8746\n",
      "Epoch 14/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4298 - accuracy: 0.8380 - val_loss: 0.4388 - val_accuracy: 0.8662\n",
      "Epoch 15/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4315 - accuracy: 0.8373 - val_loss: 0.4256 - val_accuracy: 0.8694\n",
      "Epoch 16/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4257 - accuracy: 0.8409 - val_loss: 0.4069 - val_accuracy: 0.8778\n",
      "Epoch 17/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4200 - accuracy: 0.8425 - val_loss: 0.5395 - val_accuracy: 0.8566\n",
      "Epoch 18/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4345 - accuracy: 0.8388 - val_loss: 0.4622 - val_accuracy: 0.8684\n",
      "Epoch 19/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4277 - accuracy: 0.8422 - val_loss: 0.4648 - val_accuracy: 0.8702\n",
      "Epoch 20/20\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4194 - accuracy: 0.8425 - val_loss: 0.4405 - val_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True) for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10000, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.    , 0.0012,\n",
       "        0.    , 0.9987]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.72, 0.  , 0.27]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.65, 0.  , 0.33]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.3 , 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.51]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.38, 0.  , 0.51]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.07, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.03, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.02, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.05, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.38, 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.2 , 0.  , 0.62]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.  , 0.26, 0.  , 0.52]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.24, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.37, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.7 , 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.1 , 0.  , 0.78]],\n",
       "\n",
       "       [[0.01, 0.  , 0.  , 0.  , 0.  , 0.55, 0.04, 0.04, 0.  , 0.35]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.02, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.09, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.35, 0.  , 0.58]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.18, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.36, 0.  , 0.56]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.13, 0.  , 0.62]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.52, 0.  , 0.18]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.48, 0.  , 0.  , 0.  , 0.52]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.72, 0.  , 0.22, 0.  , 0.06]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.08, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.59, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.14, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.09, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.38, 0.  , 0.03, 0.  , 0.6 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.19, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.48, 0.  , 0.2 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.15, 0.  , 0.84]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.05, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.06, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.05, 0.  , 0.79]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.37, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.02, 0.  , 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.85]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.27, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.54, 0.  , 0.12, 0.  , 0.34]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.09, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.09, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.4 , 0.  , 0.36]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.38, 0.  , 0.39, 0.  , 0.23]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.61, 0.  , 0.17, 0.  , 0.21]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.  , 0.04, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.27, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.18, 0.  , 0.78]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.22, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.06, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.92]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.19, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.19, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.03, 0.  , 0.93]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.22, 0.  , 0.77]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  , 0.  , 0.98]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.11, 0.  , 0.87]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.39, 0.  , 0.52]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.92, 0.  , 0.02, 0.  , 0.05]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.01, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.99]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.07, 0.  , 0.89]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.07, 0.  , 0.9 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.39, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.36, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.08, 0.  , 0.91]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.  , 0.97]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.44, 0.  , 0.55]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.03, 0.  , 0.96]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.05, 0.  , 0.86]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.2 , 0.  , 0.15, 0.  , 0.65]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.16, 0.  , 0.75]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.17, 0.  , 0.25]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4801 - accuracy: 0.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4801124036312103, 0.8610000014305115]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8642"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x25973aae608>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal',\n",
    "                  kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"elu\",\n",
    "                                kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 23s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=optimizer,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 2.0666 - accuracy: 0.2446 - val_loss: 1.9982 - val_accuracy: 0.2792\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.9495 - accuracy: 0.2870 - val_loss: 1.9632 - val_accuracy: 0.2656\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8725 - accuracy: 0.3191 - val_loss: 1.9206 - val_accuracy: 0.2910\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8054 - accuracy: 0.3441 - val_loss: 1.9299 - val_accuracy: 0.3042\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7533 - accuracy: 0.3631 - val_loss: 1.7661 - val_accuracy: 0.3578\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7109 - accuracy: 0.3824 - val_loss: 1.7196 - val_accuracy: 0.3824\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6716 - accuracy: 0.3957 - val_loss: 1.6776 - val_accuracy: 0.3888\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.6377 - accuracy: 0.4068 - val_loss: 1.6619 - val_accuracy: 0.4098\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6098 - accuracy: 0.4206 - val_loss: 1.6633 - val_accuracy: 0.3958\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5879 - accuracy: 0.4285 - val_loss: 1.6817 - val_accuracy: 0.3922\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5671 - accuracy: 0.4360 - val_loss: 1.6985 - val_accuracy: 0.3914\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5460 - accuracy: 0.4444 - val_loss: 1.6431 - val_accuracy: 0.4132\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5265 - accuracy: 0.4502 - val_loss: 1.6128 - val_accuracy: 0.4254\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5111 - accuracy: 0.4547 - val_loss: 1.5908 - val_accuracy: 0.4232\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4981 - accuracy: 0.4624 - val_loss: 1.5631 - val_accuracy: 0.4442\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4839 - accuracy: 0.4662 - val_loss: 1.5858 - val_accuracy: 0.4342\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4687 - accuracy: 0.4716 - val_loss: 1.5751 - val_accuracy: 0.4376\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4541 - accuracy: 0.4772 - val_loss: 1.5988 - val_accuracy: 0.4256\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4458 - accuracy: 0.4791 - val_loss: 1.5550 - val_accuracy: 0.4470\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4321 - accuracy: 0.4850 - val_loss: 1.5403 - val_accuracy: 0.4590\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4181 - accuracy: 0.4882 - val_loss: 1.5451 - val_accuracy: 0.4512\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4064 - accuracy: 0.4940 - val_loss: 1.5356 - val_accuracy: 0.4486\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3990 - accuracy: 0.4972 - val_loss: 1.5449 - val_accuracy: 0.4506\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3841 - accuracy: 0.5032 - val_loss: 1.5410 - val_accuracy: 0.4524\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3762 - accuracy: 0.5067 - val_loss: 1.5156 - val_accuracy: 0.4606\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3644 - accuracy: 0.5089 - val_loss: 1.5281 - val_accuracy: 0.4602\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3553 - accuracy: 0.5116 - val_loss: 1.5264 - val_accuracy: 0.4548\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3453 - accuracy: 0.5156 - val_loss: 1.5368 - val_accuracy: 0.4600\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3376 - accuracy: 0.5189 - val_loss: 1.5315 - val_accuracy: 0.4650\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3296 - accuracy: 0.5230 - val_loss: 1.5510 - val_accuracy: 0.4642\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.3195 - accuracy: 0.5253 - val_loss: 1.5556 - val_accuracy: 0.4538\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3105 - accuracy: 0.5286 - val_loss: 1.5321 - val_accuracy: 0.4632\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3047 - accuracy: 0.5310 - val_loss: 1.5371 - val_accuracy: 0.4678\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2965 - accuracy: 0.5300 - val_loss: 1.6144 - val_accuracy: 0.4480\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2885 - accuracy: 0.5378 - val_loss: 1.5273 - val_accuracy: 0.4650\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2761 - accuracy: 0.5402 - val_loss: 1.5437 - val_accuracy: 0.4646\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2724 - accuracy: 0.5431 - val_loss: 1.5215 - val_accuracy: 0.4718\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2659 - accuracy: 0.5437 - val_loss: 1.5366 - val_accuracy: 0.4666\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2536 - accuracy: 0.5473 - val_loss: 1.5652 - val_accuracy: 0.4604\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2431 - accuracy: 0.5538 - val_loss: 1.5570 - val_accuracy: 0.4656\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2415 - accuracy: 0.5536 - val_loss: 1.5152 - val_accuracy: 0.4734\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2307 - accuracy: 0.5576 - val_loss: 1.5431 - val_accuracy: 0.4648\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2240 - accuracy: 0.5603 - val_loss: 1.5285 - val_accuracy: 0.4736\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2162 - accuracy: 0.5648 - val_loss: 1.5422 - val_accuracy: 0.4684\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2091 - accuracy: 0.5633 - val_loss: 1.5715 - val_accuracy: 0.4698\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2037 - accuracy: 0.5669 - val_loss: 1.5258 - val_accuracy: 0.4722\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1934 - accuracy: 0.5691 - val_loss: 1.5700 - val_accuracy: 0.4678\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1889 - accuracy: 0.5725 - val_loss: 1.5665 - val_accuracy: 0.4680\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1771 - accuracy: 0.5748 - val_loss: 1.5458 - val_accuracy: 0.4694\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1759 - accuracy: 0.5759 - val_loss: 1.5781 - val_accuracy: 0.4702\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1644 - accuracy: 0.5841 - val_loss: 1.5789 - val_accuracy: 0.4688\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1576 - accuracy: 0.5822 - val_loss: 1.5653 - val_accuracy: 0.4648\n",
      "Epoch 53/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1506 - accuracy: 0.5877 - val_loss: 1.5465 - val_accuracy: 0.4818\n",
      "Epoch 54/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.1473 - accuracy: 0.5876 - val_loss: 1.5786 - val_accuracy: 0.4704\n",
      "Epoch 55/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1370 - accuracy: 0.5917 - val_loss: 1.5748 - val_accuracy: 0.4732\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1299 - accuracy: 0.5926 - val_loss: 1.5808 - val_accuracy: 0.4662\n",
      "Epoch 57/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1225 - accuracy: 0.5955 - val_loss: 1.5814 - val_accuracy: 0.4738\n",
      "Epoch 58/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1200 - accuracy: 0.5973 - val_loss: 1.5721 - val_accuracy: 0.4776\n",
      "Epoch 59/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.1149 - accuracy: 0.5993 - val_loss: 1.5751 - val_accuracy: 0.4800\n",
      "Epoch 60/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1051 - accuracy: 0.6009 - val_loss: 1.6095 - val_accuracy: 0.4676\n",
      "Epoch 61/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0951 - accuracy: 0.6047 - val_loss: 1.6214 - val_accuracy: 0.4668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c49e1bdb08>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "         validation_data=(X_valid, y_valid),\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5152 - accuracy: 0.4734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5151920318603516, 0.4733999967575073]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=optimizer,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 23s 12ms/step - loss: 1.9777 - accuracy: 0.2938 - val_loss: 1.6843 - val_accuracy: 0.4010\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6778 - accuracy: 0.4021 - val_loss: 1.5826 - val_accuracy: 0.4324\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.6117 - accuracy: 0.4305 - val_loss: 1.5100 - val_accuracy: 0.4588\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 1.5460 - accuracy: 0.4474 - val_loss: 1.5109 - val_accuracy: 0.4590\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5005 - accuracy: 0.4670 - val_loss: 1.4389 - val_accuracy: 0.4898\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4620 - accuracy: 0.4814 - val_loss: 1.4470 - val_accuracy: 0.4910\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.4262 - accuracy: 0.4922 - val_loss: 1.4115 - val_accuracy: 0.4964\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.3994 - accuracy: 0.5031 - val_loss: 1.3937 - val_accuracy: 0.5028\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.3757 - accuracy: 0.5175 - val_loss: 1.3670 - val_accuracy: 0.5166\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.3534 - accuracy: 0.5189 - val_loss: 1.3685 - val_accuracy: 0.5132\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.3284 - accuracy: 0.5319 - val_loss: 1.3540 - val_accuracy: 0.5210\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.3028 - accuracy: 0.5416 - val_loss: 1.3780 - val_accuracy: 0.5084\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 22s 16ms/step - loss: 1.2899 - accuracy: 0.5460 - val_loss: 1.3782 - val_accuracy: 0.5146\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.2646 - accuracy: 0.5530 - val_loss: 1.3457 - val_accuracy: 0.5254\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2569 - accuracy: 0.5560 - val_loss: 1.3690 - val_accuracy: 0.5262\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2422 - accuracy: 0.5629 - val_loss: 1.3510 - val_accuracy: 0.5226\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2244 - accuracy: 0.5654 - val_loss: 1.3344 - val_accuracy: 0.5278\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.2084 - accuracy: 0.5713 - val_loss: 1.3326 - val_accuracy: 0.5284\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1952 - accuracy: 0.5800 - val_loss: 1.3522 - val_accuracy: 0.5230\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1812 - accuracy: 0.5819 - val_loss: 1.3866 - val_accuracy: 0.5126\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1690 - accuracy: 0.5879 - val_loss: 1.3730 - val_accuracy: 0.5276\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1513 - accuracy: 0.5928 - val_loss: 1.3460 - val_accuracy: 0.5260\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1421 - accuracy: 0.5999 - val_loss: 1.3382 - val_accuracy: 0.5392\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1344 - accuracy: 0.5980 - val_loss: 1.3130 - val_accuracy: 0.5408\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1204 - accuracy: 0.6054 - val_loss: 1.3232 - val_accuracy: 0.5382\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.1022 - accuracy: 0.6115 - val_loss: 1.3628 - val_accuracy: 0.5324\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0922 - accuracy: 0.6139 - val_loss: 1.3524 - val_accuracy: 0.5336\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0875 - accuracy: 0.6173 - val_loss: 1.3658 - val_accuracy: 0.5218\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0855 - accuracy: 0.6175 - val_loss: 1.3379 - val_accuracy: 0.5408\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0669 - accuracy: 0.6240 - val_loss: 1.3372 - val_accuracy: 0.5420\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0655 - accuracy: 0.6236 - val_loss: 1.3431 - val_accuracy: 0.5400\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.0372 - accuracy: 0.6342 - val_loss: 1.3606 - val_accuracy: 0.5302\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0354 - accuracy: 0.6370 - val_loss: 1.3600 - val_accuracy: 0.5448\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.0277 - accuracy: 0.6369 - val_loss: 1.3314 - val_accuracy: 0.5424\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0174 - accuracy: 0.6429 - val_loss: 1.3361 - val_accuracy: 0.5418\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.0076 - accuracy: 0.6459 - val_loss: 1.3360 - val_accuracy: 0.5468\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9828 - accuracy: 0.6526 - val_loss: 1.3398 - val_accuracy: 0.5452\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9871 - accuracy: 0.6511 - val_loss: 1.3681 - val_accuracy: 0.5392\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 0.9801 - accuracy: 0.6523 - val_loss: 1.3651 - val_accuracy: 0.5342\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 0.9594 - accuracy: 0.6629 - val_loss: 1.3878 - val_accuracy: 0.5380\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9628 - accuracy: 0.6653 - val_loss: 1.3594 - val_accuracy: 0.5470\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9498 - accuracy: 0.6661 - val_loss: 1.3993 - val_accuracy: 0.5372\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9477 - accuracy: 0.6694 - val_loss: 1.3782 - val_accuracy: 0.5352\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 0.9395 - accuracy: 0.6697 - val_loss: 1.3983 - val_accuracy: 0.5312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c4a89eef88>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "         validation_data=(X_valid, y_valid),\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 2ms/step - loss: 1.3130 - accuracy: 0.5408: 0s - loss: 1.3136 - accuracy: 0.53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3129956722259521, 0.5407999753952026]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=optimizer,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 13s 8ms/step - loss: 2.0655 - accuracy: 0.2632 - val_loss: 1.8620 - val_accuracy: 0.3352\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.7475 - accuracy: 0.3760 - val_loss: 1.7397 - val_accuracy: 0.3904\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6335 - accuracy: 0.4254 - val_loss: 1.7237 - val_accuracy: 0.3930\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5572 - accuracy: 0.4494 - val_loss: 1.6405 - val_accuracy: 0.4314\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4925 - accuracy: 0.4707 - val_loss: 1.5681 - val_accuracy: 0.4496\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4340 - accuracy: 0.4973 - val_loss: 1.5565 - val_accuracy: 0.4598\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3860 - accuracy: 0.5175 - val_loss: 1.5250 - val_accuracy: 0.4546\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3464 - accuracy: 0.5296 - val_loss: 1.4834 - val_accuracy: 0.4788\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.3139 - accuracy: 0.5371 - val_loss: 1.4822 - val_accuracy: 0.4772\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.2770 - accuracy: 0.5559 - val_loss: 1.5064 - val_accuracy: 0.4876\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2446 - accuracy: 0.5730 - val_loss: 1.5498 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2301 - accuracy: 0.5804 - val_loss: 1.4684 - val_accuracy: 0.4912\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.1965 - accuracy: 0.5873 - val_loss: 1.4778 - val_accuracy: 0.5020\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.1496 - accuracy: 0.6073 - val_loss: 1.4659 - val_accuracy: 0.5114\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1436 - accuracy: 0.6070 - val_loss: 1.5204 - val_accuracy: 0.5060\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1204 - accuracy: 0.6164 - val_loss: 1.5405 - val_accuracy: 0.5104\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1126 - accuracy: 0.6194 - val_loss: 1.4978 - val_accuracy: 0.5090\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0949 - accuracy: 0.6260 - val_loss: 1.7512 - val_accuracy: 0.3802\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4276 - accuracy: 0.4987 - val_loss: 1.5624 - val_accuracy: 0.4830\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1795 - accuracy: 0.5932 - val_loss: 1.5455 - val_accuracy: 0.4946\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.0993 - accuracy: 0.6203 - val_loss: 1.5492 - val_accuracy: 0.4856\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.0534 - accuracy: 0.6394 - val_loss: 1.5358 - val_accuracy: 0.5086\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.0155 - accuracy: 0.6503 - val_loss: 1.5311 - val_accuracy: 0.5046\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0081 - accuracy: 0.6601 - val_loss: 1.5642 - val_accuracy: 0.5028\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0080 - accuracy: 0.6564 - val_loss: 1.5221 - val_accuracy: 0.5126\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9775 - accuracy: 0.6666 - val_loss: 1.5579 - val_accuracy: 0.5134\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9648 - accuracy: 0.6720 - val_loss: 1.5266 - val_accuracy: 0.5126\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9698 - accuracy: 0.6682 - val_loss: 1.6028 - val_accuracy: 0.5046\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9399 - accuracy: 0.6827 - val_loss: 1.5845 - val_accuracy: 0.5150\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2032 - accuracy: 0.6760 - val_loss: 1.5457 - val_accuracy: 0.4940\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 0.9892 - accuracy: 0.6593 - val_loss: 1.5560 - val_accuracy: 0.5044\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9144 - accuracy: 0.6854 - val_loss: 1.6128 - val_accuracy: 0.5182\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8919 - accuracy: 0.6902 - val_loss: 34827.9883 - val_accuracy: 0.5144\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8499 - accuracy: 0.7128 - val_loss: 1.6203 - val_accuracy: 0.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c49e314588>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "         validation_data=(X_valid_scaled, y_valid),\n",
    "         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4659 - accuracy: 0.5114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.465861439704895, 0.5113999843597412]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=optimizer,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1407/1407 [==============================] - 12s 7ms/step - loss: 2.0662 - accuracy: 0.2790 - val_loss: 1.7548 - val_accuracy: 0.3746\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.6735 - accuracy: 0.4091 - val_loss: 1.7257 - val_accuracy: 0.3886\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.5859 - accuracy: 0.4471 - val_loss: 1.6619 - val_accuracy: 0.4228\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.5073 - accuracy: 0.4702 - val_loss: 1.5918 - val_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.4431 - accuracy: 0.4947 - val_loss: 1.5637 - val_accuracy: 0.4756\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3919 - accuracy: 0.5115 - val_loss: 1.5364 - val_accuracy: 0.4748\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3476 - accuracy: 0.5302 - val_loss: 1.6293 - val_accuracy: 0.4728\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3030 - accuracy: 0.5495 - val_loss: 1.5108 - val_accuracy: 0.4954\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2746 - accuracy: 0.5563 - val_loss: 1.5144 - val_accuracy: 0.4848\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2357 - accuracy: 0.5698 - val_loss: 1.6140 - val_accuracy: 0.4900\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1928 - accuracy: 0.5933 - val_loss: 1.6299 - val_accuracy: 0.4946\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1641 - accuracy: 0.5958 - val_loss: 1.5393 - val_accuracy: 0.5006\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1362 - accuracy: 0.6071 - val_loss: 1.5672 - val_accuracy: 0.4984\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.1034 - accuracy: 0.6196 - val_loss: 1.5304 - val_accuracy: 0.5068\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0935 - accuracy: 0.6202 - val_loss: 1.5851 - val_accuracy: 0.5114\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0655 - accuracy: 0.6341 - val_loss: 1.5808 - val_accuracy: 0.5154\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.0384 - accuracy: 0.6459 - val_loss: 1.6020 - val_accuracy: 0.5006\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0211 - accuracy: 0.6516 - val_loss: 1.6708 - val_accuracy: 0.5086\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9955 - accuracy: 0.6607 - val_loss: 1.7259 - val_accuracy: 0.5098\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9772 - accuracy: 0.6640 - val_loss: 1.6568 - val_accuracy: 0.5080\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9571 - accuracy: 0.6733 - val_loss: 1.7179 - val_accuracy: 0.5042\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9356 - accuracy: 0.6826 - val_loss: 1.7595 - val_accuracy: 0.5010\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9209 - accuracy: 0.6898 - val_loss: 1.7627 - val_accuracy: 0.4914\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9228 - accuracy: 0.6882 - val_loss: 1.7302 - val_accuracy: 0.5040\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8926 - accuracy: 0.6990 - val_loss: 1.8374 - val_accuracy: 0.5100\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8543 - accuracy: 0.7108 - val_loss: 1.8774 - val_accuracy: 0.4898\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8575 - accuracy: 0.7118 - val_loss: 1.7643 - val_accuracy: 0.5160\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8397 - accuracy: 0.7194 - val_loss: 1.8331 - val_accuracy: 0.4908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c4984b46c8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5108 - accuracy: 0.4954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5108253955841064, 0.49540001153945923]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4974"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=optimizer,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 3s 8ms/step - loss: nan - accuracy: 0.1245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1e-05, 9.999868, 2.619798421859741, 3.937614474977766]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    \n",
    "\n",
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1,\n",
    "                                  batch_size=batch_size)\n",
    "\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 4s 9ms/step - loss: 2.2259 - accuracy: 0.2363 - val_loss: 1.7972 - val_accuracy: 0.3792\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.7821 - accuracy: 0.3706 - val_loss: 1.6632 - val_accuracy: 0.4108\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.6381 - accuracy: 0.4194 - val_loss: 1.6363 - val_accuracy: 0.4308\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.5439 - accuracy: 0.4504 - val_loss: 1.6249 - val_accuracy: 0.4326\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.4864 - accuracy: 0.4749 - val_loss: 1.6101 - val_accuracy: 0.4566\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.4395 - accuracy: 0.4859 - val_loss: 1.5485 - val_accuracy: 0.4676\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.4064 - accuracy: 0.5004 - val_loss: 1.5736 - val_accuracy: 0.4540\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.3472 - accuracy: 0.5214 - val_loss: 1.4937 - val_accuracy: 0.4842\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2727 - accuracy: 0.5452 - val_loss: 1.5212 - val_accuracy: 0.4748\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.1963 - accuracy: 0.5699 - val_loss: 1.5377 - val_accuracy: 0.4946\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.1201 - accuracy: 0.6008 - val_loss: 1.5381 - val_accuracy: 0.5048\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0656 - accuracy: 0.6205 - val_loss: 1.5025 - val_accuracy: 0.5098\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9885 - accuracy: 0.6488 - val_loss: 1.5509 - val_accuracy: 0.5130\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.9156 - accuracy: 0.6761 - val_loss: 1.5552 - val_accuracy: 0.5214\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.8856 - accuracy: 0.6858 - val_loss: 1.5779 - val_accuracy: 0.5264\n"
     ]
    }
   ],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)\n",
    "\n",
    "n_epochs = 15\n",
    "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                   validation_data=(X_valid_scaled, y_valid),\n",
    "                   callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
